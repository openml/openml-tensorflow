{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Tensorflow extension for OpenML python","text":"<p>Tensorflow extension for openml-python API. This library provides a simple way to run your Tensorflow models on OpenML tasks. </p>"},{"location":"#installation-instructions","title":"Installation Instructions:","text":"<p><code>pip install openml-tensorflow</code></p> <p>PyPi link https://pypi.org/project/openml-tensorflow/</p>"},{"location":"#usage","title":"Usage","text":"<p>Import openML libraries <pre><code>import openml\nimport openml_tensorflow\nfrom tensorflow.keras import layers, models\n</code></pre> Create  and compile a tensorflow model <pre><code>model = models.Sequential()\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu', input_shape=IMG_SHAPE))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dense(84, activation='relu'))\nmodel.add(layers.Dense(19, activation='softmax'))  \nmodel.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['AUC'])\n\n# We will compile using the Adam optimizer while targeting accuracy.\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['AUC'])\n</code></pre> Download the task from openML and run the model on task. <pre><code>task = openml.tasks.get_task(362071)\nrun = openml.runs.run_model_on_task(model, task, avoid_duplicate_runs=False)\nrun.publish()\nprint('URL for run: %s/run/%d' % (openml.config.server, run.run_id))\n</code></pre></p> <p>Note: The input layer of the network should be compatible with OpenML data output shape. Please check examples for more information.</p> <p>Additionally, if you want to publish the run with onnx file, then you must call <code>openml_tensorflow.add_onnx_to_run()</code> immediately before <code>run.publish()</code>. </p> <pre><code>run = openml_tensorflow.add_onnx_to_run(run)\n</code></pre>"},{"location":"#using-docker-image","title":"Using docker image","text":"<p>The docker container has the latest version of OpenML-Tensorflow downloaded and pre-installed. It can be used to run TensorFlow Deep Learning analysis on OpenML datasets.  See docker.</p> <p>This library is currently under development, please report any bugs or feature request in issues section.</p>"},{"location":"Limitations%20of%20the%20API/","title":"Limitations","text":"<ul> <li>Image datasets are supported in OpenML as a workaround by using a CSV file with image paths. This is not ideal and might eventually be replaced by something else. At the moment, the focus is on tabular data.</li> <li>OpenML-Tensorflow API currently only supports runs on image datasets. Other modalities will be included in the future.   </li> <li>Many features (like custom metrics, models etc) are still dependant on the OpenML Python API, which is in the middle of a major rewrite. Until that is complete, this package will not be able to provide all the features it aims to.</li> </ul>"},{"location":"API%20reference/Config/","title":"Config","text":"<p>Config file to define all hyperparameters.</p> <pre><code>from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nepoch = 10\nbatch_size = 32\ndatagen = ImageDataGenerator()\nstep_per_epoch = 100\ntarget_size = (128, 128)\nx_col = None\ny_col = None  # TODO: Remove? This is not used if a task is defined.\n\nperform_validation = False\nvalidation_split = 0.1  # The percentage of data set aside for the validation set\nvalidation_steps = 1\ndatagen_valid = ImageDataGenerator()\nkwargs = {}\n</code></pre>"},{"location":"API%20reference/OpenML%20integration/","title":"OpenML Integration","text":""},{"location":"API%20reference/OpenML%20integration/#extension.TensorflowExtension","title":"<code>TensorflowExtension</code>","text":"<p>               Bases: <code>Extension</code></p> <p>Connect Keras to OpenML-Python.</p> Source code in <code>openml_tensorflow/extension.py</code> <pre><code>class TensorflowExtension(Extension):\n    \"\"\"Connect Keras to OpenML-Python.\"\"\"\n\n    ################################################################################################\n    # General setup\n\n    @classmethod\n    def can_handle_flow(cls, flow: 'OpenMLFlow') -&gt; bool:\n        \"\"\"Check whether a given flow describes a Keras neural network.\n\n        This is done by parsing the ``external_version`` field.\n\n        Parameters\n        ----------\n        flow : OpenMLFlow\n\n        Returns\n        -------\n        bool\n        \"\"\"\n        return cls._is_tf_flow(flow)\n\n    @classmethod\n    def can_handle_model(cls, model: Any) -&gt; bool:\n        \"\"\"Check whether a model is an instance of ``tf.models.Model``.\n\n        Parameters\n        ----------\n        model : Any\n\n        Returns\n        -------\n        bool\n        \"\"\"\n        return isinstance(model, tensorflow.keras.models.Model)\n\n    ################################################################################################\n    # Methods for flow serialization and de-serialization\n\n    def flow_to_model(self, flow: 'OpenMLFlow', initialize_with_defaults: bool = False) -&gt; Any:\n        \"\"\"Initializes a Keras model based on a flow.\n\n        Parameters\n        ----------\n        flow : mixed\n            the object to deserialize (can be flow object, or any serialized\n            parameter value that is accepted by)\n\n        initialize_with_defaults : bool, optional (default=False)\n            If this flag is set, the hyperparameter values of flows will be\n            ignored and a flow with its defaults is returned.\n\n        Returns\n        -------\n        mixed\n        \"\"\"\n        return self._deserialize_tf(flow, initialize_with_defaults=initialize_with_defaults)\n\n    def _deserialize_tf(\n            self,\n            o: Any,\n            components: Optional[Dict] = None,\n            initialize_with_defaults: bool = False,\n            recursion_depth: int = 0,\n    ) -&gt; Any:\n        \"\"\"\n        Recursive function to deserialize a tensorflow flow.\n\n        This function delegates all work to the respective functions to deserialize special data\n        structures etc.\n\n        Parameters\n        ----------\n        o : mixed\n            the object to deserialize (can be flow object, or any serialized\n            parameter value that is accepted by)\n\n        components : dict\n            empty\n\n        initialize_with_defaults : bool, optional (default=False)\n            If this flag is set, the hyperparameter values of flows will be\n            ignored and a flow with its defaults is returned.\n\n        recursion_depth : int\n            The depth at which this flow is called, mostly for debugging\n            purposes\n\n        Returns\n        -------\n        mixed\n        \"\"\"\n        logging.info('-%s flow_to_keras START o=%s, components=%s, '\n                     'init_defaults=%s' % ('-' * recursion_depth, o, components,\n                                           initialize_with_defaults))\n        depth_pp = recursion_depth + 1  # shortcut var, depth plus plus\n\n        # First, we need to check whether the presented object is a json string.\n        # JSON strings are used to encoder parameter values. By passing around\n        # json strings for parameters, we make sure that we can flow_to_keras\n        # the parameter values to the correct type.\n        if isinstance(o, str):\n            try:\n                o = json.loads(o)\n                try:\n                    o = o[0:1000]\n                except:\n                    pass\n            except JSONDecodeError:\n                pass\n\n        rval = None  # type: Any\n        if isinstance(o, dict):\n            rval = dict(\n                (\n                    self._deserialize_tf(\n                        o=key,\n                        components=components,\n                        initialize_with_defaults=initialize_with_defaults,\n                        recursion_depth=depth_pp,\n                    ),\n                    self._deserialize_tf(\n                        o=value,\n                        components=components,\n                        initialize_with_defaults=initialize_with_defaults,\n                        recursion_depth=depth_pp,\n                    )\n                )\n                for key, value in sorted(o.items())\n            )\n        elif isinstance(o, (list, tuple)):\n            rval = [\n                self._deserialize_tf(\n                    o=element,\n                    components=components,\n                    initialize_with_defaults=initialize_with_defaults,\n                    recursion_depth=depth_pp,\n                )\n                for element in o\n            ]\n            if isinstance(o, tuple):\n                rval = tuple(rval)\n        elif isinstance(o, (bool, int, float, str)) or o is None:\n            try:\n                rval = o[0:100]\n            except:\n                rval = o\n        elif isinstance(o, OpenMLFlow):\n            if not self._is_tf_flow(o):\n                raise ValueError('Only Tensorflow flows can be reinstantiated')\n            rval = self._deserialize_model(\n                flow=o,\n                keep_defaults=initialize_with_defaults,\n                recursion_depth=recursion_depth,\n            )\n        else:\n            raise TypeError(o)\n        logging.info('-%s flow_to_tf END   o=%s, rval=%s'\n                     % ('-' * recursion_depth, o, rval))\n        return rval\n\n    def model_to_flow(self, model: Any) -&gt; 'OpenMLFlow':\n        \"\"\"Transform a Keras model to a flow for uploading it to OpenML.\n\n        Parameters\n        ----------\n        model : Any\n\n        Returns\n        -------\n        OpenMLFlow\n        \"\"\"\n        # Necessary to make pypy not complain about all the different possible return types\n        return self._serialize_tf(model)\n\n    def _serialize_tf(self, o: Any, parent_model: Optional[Any] = None) -&gt; Any:\n        rval = None  # type: Any\n        if self.is_estimator(o):\n            # is the main model or a submodel\n            rval = self._serialize_model(o)\n        elif isinstance(o, (list, tuple)):\n            rval = [self._serialize_tf(element, parent_model) for element in o]\n            if isinstance(o, tuple):\n                rval = tuple(rval)\n        elif isinstance(o, SIMPLE_TYPES) or o is None:\n            if isinstance(o, tuple(SIMPLE_NUMPY_TYPES)):\n                o = o.item()\n            # base parameter values\n            rval = o\n        elif isinstance(o, dict):\n            if not isinstance(o, OrderedDict):\n                o = OrderedDict([(key, value) for key, value in sorted(o.items())])\n\n            rval = OrderedDict()\n            for key, value in o.items():\n                if not isinstance(key, str):\n                    raise TypeError('Can only use string as keys, you passed '\n                                    'type %s for value %s.' %\n                                    (type(key), str(key)))\n                key = self._serialize_tf(key, parent_model)\n                value = self._serialize_tf(value, parent_model)\n                rval[key] = value\n            rval = rval\n            # Not sure below limit is used for reducing paramter size. \n            # if len(rval.keys()) &gt; 15:\n            #    rval = rval[list(rval.keys())[0]]\n        else:\n            if type(o) == np.ndarray:\n                rval=o.item()\n            else:\n                if 'keras.src.metrics.base_metric.Mean' in str(type(o)):\n                   rval = o._name\n                #   This elif is only to make it compatibile with tensorflow version-2.10.0\n                elif 'keras.metrics.base_metric.Mean' in str(type(o)):\n                    rval = o._name\n                else:\n                   raise TypeError(o, type(o))\n        return rval\n    def get_version_information(self) -&gt; List[str]:\n        \"\"\"List versions of libraries required by the flow.\n\n        Libraries listed are ``Python``, ``tensorflow``, ``numpy`` and ``scipy``.\n\n        Returns\n        -------\n        List\n        \"\"\"\n\n        import tensorflow\n        import scipy\n        import numpy\n\n        major, minor, micro, _, _ = sys.version_info\n        python_version = 'Python_{}.'.format(\n            \".\".join([str(major), str(minor), str(micro)]))\n        tensorflow_version = 'tensorflow_{}.'.format(tensorflow.__version__)\n        numpy_version = 'NumPy_{}.'.format(numpy.__version__)\n        scipy_version = 'SciPy_{}.'.format(scipy.__version__)\n\n        return [python_version, tensorflow_version, numpy_version, scipy_version]\n\n    def create_setup_string(self, model: Any) -&gt; str:\n        \"\"\"Create a string which can be used to reinstantiate the given model.\n\n        Parameters\n        ----------\n        model : Any\n\n        Returns\n        -------\n        str\n        \"\"\"\n        run_environment = \" \".join(self.get_version_information())\n        return run_environment + \" \" + str(model)\n\n    @classmethod\n    def _is_tf_flow(cls, flow: OpenMLFlow) -&gt; bool:\n#        breakpoint()\n        return (flow.external_version.startswith('keras==')\n                or ',tensorflow==' in flow.external_version)\n\n    def _serialize_model(self, model: Any) -&gt; OpenMLFlow:\n        \"\"\"Create an OpenMLFlow.\n\n        Calls `tf_to_flow` recursively to properly serialize the\n        parameters to strings and the components (other models) to OpenMLFlows.\n\n        Parameters\n        ----------\n        model : Keras neural network\n\n        Returns\n        -------\n        OpenMLFlow\n\n        \"\"\"\n        # Get all necessary information about the model objects itself\n        parameters, parameters_meta_info, subcomponents, subcomponents_explicit = \\\n            self._extract_information_from_model(model)\n\n        # Create a flow name, which contains a hash of the parameters as part of the name\n        # This is done in order to ensure that we are not exceeding the 1024 character limit\n        # of the API, since NNs can become quite large\n        class_name = \"tensorflow.\" + model.__module__ + \".\" + model.__class__.__name__\n        class_name += '.' + format(\n            zlib.crc32(json.dumps(parameters, sort_keys=True).encode('utf8')),\n            'x'\n        )\n\n        external_version = self._get_external_version_string(model, subcomponents)\n        name = class_name\n\n        dependencies = '\\n'.join([\n            self._format_external_version(\n                'tensorflow',\n                tensorflow.__version__,\n            ),\n            'numpy&gt;=1.6.1',\n            'scipy&gt;=0.9',\n        ])\n\n        tensorflow_version = self._format_external_version('tensorflow', tensorflow.__version__)\n        tensorflow_version_formatted = tensorflow_version.replace('==', '_')\n        flow = OpenMLFlow(name=name,\n                          class_name=class_name,\n                          description='Automatically created tensorflow flow.',\n                          model=model,\n                          components=subcomponents,\n                          parameters=parameters,\n                          parameters_meta_info=parameters_meta_info,\n                          external_version=external_version,\n                          tags=['openml-python', 'tensorflow',\n                                'python', tensorflow_version_formatted,\n\n                                ],\n                          language='English',\n                          dependencies=dependencies)\n        return flow\n\n    def _get_external_version_string(\n            self,\n            model: Any,\n            sub_components: Dict[str, OpenMLFlow],\n    ) -&gt; str:\n        # Create external version string for a flow, given the model and the\n        # already parsed dictionary of sub_components. Retrieves the external\n        # version of all subcomponents, which themselves already contain all\n        # requirements for their subcomponents. The external version string is a\n        # sorted concatenation of all modules which are present in this run.\n        model_package_name = model.__module__.split('.')[0]\n        module = importlib.import_module(model_package_name)\n        model_package_version_number = module.__version__  # type: ignore\n        external_version = self._format_external_version(\n            model_package_name, model_package_version_number,\n        )\n        openml_version = self._format_external_version('openml', openml.__version__)\n        external_versions = set()\n        external_versions.add(external_version)\n        external_versions.add(openml_version)\n        for visitee in sub_components.values():\n            for external_version in visitee.external_version.split(','):\n                external_versions.add(external_version)\n\n        return ','.join(list(sorted(external_versions)))\n\n    def _from_parameters(self, parameters: 'OrderedDict[str, Any]') -&gt; Any:\n        \"\"\" Get a tensorflow model from flow parameters \"\"\"\n\n        # Create a dict and recursively fill it with model components\n        # First do this for non-layer items, then layer items.\n        config = {}\n\n        # Add the expected configuration parameters back to the configuration dictionary,\n        # as long as they are not layers, since they need to be deserialized separately\n        for k, v in parameters.items():\n            if not LAYER_PATTERN.match(k):\n                config[k] = self._deserialize_tf(v)\n\n        # Recreate the layers list and start to deserialize them back to the correct location\n        config['config']['layers'] = []\n        for k, v in parameters.items():\n            if LAYER_PATTERN.match(k):\n                v = self._deserialize_tf(v)\n                config['config']['layers'].append(v)\n\n        # Deserialize the model from the configuration dictionary\n        model = tensorflow.keras.layers.deserialize(config)\n\n        # Attempt to recompile the model if compilation parameters were present\n        # during serialization\n        if 'optimizer' in parameters:\n            training_config = self._deserialize_tf(parameters['optimizer'])\n            optimizer_config = training_config['optimizer_config']\n            optimizer = tensorflow.keras.optimizers.deserialize(optimizer_config)\n\n            # Recover loss functions and metrics\n            loss = training_config['loss']\n            metrics = training_config['metrics']\n            sample_weight_mode = training_config.get('sample_weight_mode', None)\n            loss_weights = training_config.get('loss_weights', None)\n\n            # Compile model\n            model.compile(optimizer=optimizer,\n                          loss=loss,\n                          metrics=metrics,\n                          loss_weights=loss_weights,\n                          sample_weight_mode=sample_weight_mode)\n        else:\n            warnings.warn('No training configuration found inside the flow: '\n                          'the model was *not* compiled. '\n                          'Compile it manually.')\n\n        return model \n\n    def _get_parameters(self, model: Any) -&gt; 'OrderedDict[str, Optional[str]]':\n        # Get the parameters from a model in an OrderedDict\n        parameters = OrderedDict()  # type: OrderedDict[str, Any]\n\n        # Construct the configuration dictionary in the same manner as\n        # keras.engine.Network.to_json does\n        model_config = {\n            'class_name': model.__class__.__name__,\n            'config': model.get_config(),\n            'tensorflow_version': tensorflow.__version__,\n            'backend': tensorflow.keras.backend.backend()\n        }\n        layers = []\n\n        # In some cases a layer can be a complete pretrained model (eg transfer learning). \n        # Hence 'layer' list for such layers are flattened so that each layer of the pretrained model \n        # is treated separately. this is to ensure OpenML server donot run into limit error while publishing the model. \n        for i in range(len(model_config['config']['layers'])):\n            if 'layers' in model_config['config']['layers'][i]['config'].keys():\n                layers.extend(model_config['config']['layers'][i]['config']['layers'])\n            else:\n                layers.append(model_config['config']['layers'][i])    \n\n        # Remove the layers from the configuration in order to allow them to be\n        # pretty printed as model parameters\n        del model_config['config']['layers']\n\n        # Add the rest of the model configuration entries to the parameter list\n        for k, v in model_config.items():\n            parameters[k] = self._serialize_tf(v, model)\n\n        # Compute the format of the layer numbering. This pads the layer numbers with 0s in\n        # order to ensure that the layers are printed in a human-friendly order, instead of\n        # having weird orderings\n        max_len = int(np.ceil(np.log10(len(layers))))\n        len_format = '{0:0&gt;' + str(max_len) + '}'\n\n        # Add the layers as hyper-parameters\n        for i, v in enumerate(layers):\n            layer = v['config']\n            # Some models contain \"/\" in layer name to denote hirerachy, while some denote it using \"_\"\n            # To correct this all \"/\" in layer[name] is replaced by \"_\"\n            k = 'layer' + len_format.format(i) + \"_\" + layer['name'].replace('/', '_')\n            parameters[k] = self._serialize_tf(v, model)\n\n        # Introduce the optimizer settings as hyper-parameters, if the model has been compiled\n        if model.optimizer:\n            parameters['optimizer'] = self._serialize_tf({\n                'optimizer_config': {\n                    'class_name': model.optimizer.__class__.__name__,\n                    'config': model.optimizer.get_config()\n                },\n                'loss': model.loss,\n                'metrics': model.metrics,\n                # 'weighted_metrics': model.metrics,\n                # 'sample_weight_mode': model.sample_weight_mode,\n                # 'loss_weights': model.loss_weights,\n            }, model)\n\n        return parameters\n\n    def _extract_information_from_model(\n            self,\n            model: Any,\n    ) -&gt; Tuple[\n        'OrderedDict[str, Optional[str]]',\n        'OrderedDict[str, Optional[Dict]]',\n        'OrderedDict[str, OpenMLFlow]',\n        Set,\n    ]:\n        # Stores all entities that should become subcomponents (unused)\n        sub_components = OrderedDict()  # type: OrderedDict[str, OpenMLFlow]\n        # Stores the keys of all subcomponents that should become (unused)\n        sub_components_explicit = set()  # type: Set\n        parameters = OrderedDict()  # type: OrderedDict[str, Optional[str]]\n        parameters_meta_info = OrderedDict()  # type: OrderedDict[str, Optional[Dict]]\n\n        model_parameters = self._get_parameters(model)\n        for k, v in sorted(model_parameters.items(), key=lambda t: t[0]):\n            rval = self._serialize_tf(v, model)\n            rval = json.dumps(rval)\n\n            parameters[k] = rval\n            parameters_meta_info[k] = OrderedDict((('description', None), ('data_type', None)))\n\n        return parameters, parameters_meta_info, sub_components, sub_components_explicit\n\n    def _deserialize_model(\n            self,\n            flow: OpenMLFlow,\n            keep_defaults: bool,\n            recursion_depth: int,\n    ) -&gt; Any:\n        logging.info('-%s deserialize %s' % ('-' * recursion_depth, flow.name))\n        self._check_dependencies(flow.dependencies)\n\n        parameters = flow.parameters\n        components = flow.components\n        parameter_dict = OrderedDict()  # type: OrderedDict[str, Any]\n\n        # Do a shallow copy of the components dictionary so we can remove the\n        # components from this copy once we added them into the layer list. This\n        # allows us to not consider them any more when looping over the\n        # components, but keeping the dictionary of components untouched in the\n        # original components dictionary.\n        components_ = copy.copy(components)\n\n        for name in parameters:\n            value = parameters.get(name)\n            logging.info('--%s flow_parameter=%s, value=%s' %\n                         ('-' * recursion_depth, name, value))\n            rval = self._deserialize_tf(\n                value,\n                components=components_,\n                initialize_with_defaults=keep_defaults,\n                recursion_depth=recursion_depth + 1,\n            )\n            parameter_dict[name] = rval\n\n        for name in components:\n            if name in parameter_dict:\n                continue\n            if name not in components_:\n                continue\n            value = components[name]\n            logging.info('--%s flow_component=%s, value=%s'\n                         % ('-' * recursion_depth, name, value))\n            rval = self._deserialize_tf(\n                value,\n                recursion_depth=recursion_depth + 1,\n            )\n            parameter_dict[name] = rval\n\n        return self._from_parameters(parameter_dict)\n\n    def _check_dependencies(self, dependencies: str) -&gt; None:\n        \"\"\"\n        Checks whether the dependencies required for the deserialization of an OpenMLFlow are met\n\n        Parameters\n        ----------\n        dependencies : str\n            a string representing the required dependencies\n\n        Returns\n        -------\n        None\n        \"\"\"\n        if not dependencies:\n            return\n\n        dependencies_list = dependencies.split('\\n')\n        for dependency_string in dependencies_list:\n            match = DEPENDENCIES_PATTERN.match(dependency_string)\n            if not match:\n                raise ValueError('Cannot parse dependency %s' % dependency_string)\n\n            dependency_name = match.group('name')\n            operation = match.group('operation')\n            version = match.group('version')\n\n            module = importlib.import_module(dependency_name)\n            required_version = LooseVersion(version)\n            installed_version = LooseVersion(module.__version__)  # type: ignore\n\n            if operation == '==':\n                check = required_version == installed_version\n            elif operation == '&gt;':\n                check = installed_version &gt; required_version\n            elif operation == '&gt;=':\n                check = (installed_version &gt; required_version\n                         or installed_version == required_version)\n            else:\n                raise NotImplementedError(\n                    'operation \\'%s\\' is not supported' % operation)\n            if not check:\n                raise ValueError('Trying to deserialize a model with dependency '\n                                 '%s not satisfied.' % dependency_string)\n\n    def _format_external_version(\n            self,\n            model_package_name: str,\n            model_package_version_number: str,\n    ) -&gt; str:\n        \"\"\"\n        Returns a formatted string representing the required dependencies for a flow\n\n        Parameters\n        ----------\n        model_package_name : str\n            the name of the required package\n        model_package_version_number : str\n            the version of the required package\n        Returns\n        -------\n        str\n        \"\"\"\n        return '%s==%s' % (model_package_name, model_package_version_number)\n\n    ################################################################################################\n    # Methods for performing runs with extension modules\n\n    def is_estimator(self, model: Any) -&gt; bool:\n        \"\"\"Check whether the given model is a Keras neural network.\n\n        This function is only required for backwards compatibility and will be removed in the\n        near future.\n\n        Parameters\n        ----------\n        model : Any\n\n        Returns\n        -------\n        bool\n        \"\"\"\n        return isinstance(model, tensorflow.keras.models.Model)\n\n    def seed_model(self, model: Any, seed: Optional[int] = None) -&gt; Any:\n        \"\"\"\n        Not applied for Keras, since there are no random states in Keras.\n\n        Parameters\n        ----------\n        model : keras model\n            The model to be seeded\n        seed : int\n            The seed to initialize the RandomState with. Unseeded subcomponents\n            will be seeded with a random number from the RandomState.\n\n        Returns\n        -------\n        Any\n        \"\"\"\n\n        return model\n\n    def _run_model_on_fold(\n            self,\n            model: Any,\n            task: 'OpenMLTask',\n            X_train: Union[np.ndarray, scipy.sparse.spmatrix, pd.DataFrame],\n            rep_no: int,\n            fold_no: int,\n            y_train: Optional[np.ndarray] = None,\n            X_test: Optional[Union[np.ndarray, scipy.sparse.spmatrix, pd.DataFrame]] = None,\n    ) -&gt; Tuple[\n        np.ndarray,\n        np.ndarray,\n        'OrderedDict[str, float]',\n        Optional[OpenMLRunTrace],\n        Optional[Any]\n    ]:\n        \"\"\"Run a model on a repeat,fold,subsample triplet of the task and return prediction\n        information.\n\n        Furthermore, it will measure run time measures in case multi-core behaviour allows this.\n        * exact user cpu time will be measured if the number of cores is set (recursive throughout\n        the model) exactly to 1\n        * wall clock time will be measured if the number of cores is set (recursive throughout the\n        model) to any given number (but not when it is set to -1)\n\n        Returns the data that is necessary to construct the OpenML Run object. Is used by\n        run_task_get_arff_content. Do not use this function unless you know what you are doing.\n\n        Parameters\n        ----------\n        model : Any\n            The UNTRAINED model to run. The model instance will be copied and not altered.\n        task : OpenMLTask\n            The task to run the model on.\n        X_train : array-like\n            Training data for the given repetition and fold.\n        rep_no : int\n            The repeat of the experiment (0-based; in case of 1 time CV, always 0)\n        fold_no : int\n            The fold nr of the experiment (0-based; in case of holdout, always 0)\n        y_train : Optional[np.ndarray] (default=None)\n            Target attributes for supervised tasks. In case of classification, these are integer\n            indices to the potential classes specified by dataset.\n        X_test : Optional, array-like (default=None)\n            Test attributes to test for generalization in supervised tasks.\n\n        Returns\n        -------\n        predictions : np.ndarray\n            Model predictions.\n        probabilities :  Optional, np.ndarray\n            Predicted probabilities (only applicable for supervised classification tasks).\n        user_defined_measures : OrderedDict[str, float]\n            User defined measures that were generated on this fold\n        trace : Optional, OpenMLRunTrace\n            Hyperparameter optimization trace (only applicable for supervised tasks with\n            hyperparameter optimization).\n        additional_information: Optional, Any\n            Additional information provided by the extension to be converted into additional files.\n        \"\"\"\n\n        def _prediction_to_probabilities(y: np.ndarray, classes: List[Any]) -&gt; np.ndarray:\n            \"\"\"Transforms predicted probabilities to match with OpenML class indices.\n\n            Parameters\n            ----------\n            y : np.ndarray\n                Predicted probabilities (possibly omitting classes if they were not present in the\n                training data).\n            model_classes : list\n                List of classes known_predicted by the model, ordered by their index.\n\n            Returns\n            -------\n            np.ndarray\n            \"\"\"\n            # y: list or numpy array of predictions\n            # model_classes: keras classifier mapping from original array id to\n            # prediction index id\n            if not isinstance(classes, list):\n                raise ValueError('please convert model classes to list prior to '\n                                 'calling this fn')\n            result = np.zeros((len(y), len(classes)), dtype=np.float32)\n            for obs, prediction_idx in enumerate(y):\n                result[obs][prediction_idx] = 1.0\n            return result\n\n        if isinstance(task, OpenMLSupervisedTask):\n            if y_train is None:\n                raise TypeError('argument y_train must not be of type None')\n            if X_test is None:\n                raise TypeError('argument X_test must not be of type None')\n\n        # This might look like a hack, and it is, but it maintains the compilation status,\n        # in contrast to clone_model, and also is faster than using get_config + load_from_config\n        # since it avoids string parsing\n        import dill\n        import weakref\n        model_copy = dill.loads(dill.dumps(model))\n        # model_copy = tensorflow.keras.models.clone_model(model, input_tensors=None, clone_function=None)\n        #model_copy = pickle.loads(pickle.dumps(model))\n        user_defined_measures = OrderedDict()  # type: 'OrderedDict[str, float]'\n\n        #from sklearn import preprocessing\n        #le = preprocessing.LabelEncoder()\n        #print(\"y_train\",y_train)\n        #X_train['encoded_labels'] = le.fit(y_train).transform(y_train)\n        #X_train['encoded_labels'] = X_train['encoded_labels'].astype(\"string\")\n\n        X_train['labels'] = y_train\n        #print(\"labels\",X_train['labels'])\n        class_names = sorted(y_train.unique())\n        #print(\"classes\", class_names)\n\n        kwargs = config.kwargs if config.kwargs is not None else {}\n\n\n        if config.perform_validation:\n\n            from sklearn.model_selection import train_test_split\n            from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n            # TODO: Here we're assuming that X has a label column, this won't work in general\n            X_train_train, x_val = train_test_split(X_train, test_size=config.validation_split, shuffle=True, stratify=X_train['labels'], random_state=0)\n\n            datagen_train = config.datagen\n            train_generator = datagen_train.flow_from_dataframe(dataframe=X_train_train, \n                                            directory=config.dir,\n                                            x_col=config.x_col, y_col='labels',\n                                            class_mode=\"categorical\",\n                                            classes = class_names,\n                                            target_size=config.target_size,\n                                            batch_size=config.batch_size)\n\n            datagen_valid = config.datagen_valid\n            valid_generator = datagen_valid.flow_from_dataframe(dataframe=x_val,\n                                            directory=config.dir,\n                                            x_col=config.x_col, y_col='labels',\n                                            class_mode=\"categorical\",\n                                            classes = class_names,\n                                            target_size=config.target_size,\n                                            batch_size=config.batch_size)\n        else:\n            from tensorflow.keras.preprocessing.image import ImageDataGenerator\n            datagen = config.datagen\n            train_generator = datagen.flow_from_dataframe(dataframe=X_train, directory=config.dir,\n                                            x_col=config.x_col, y_col='labels',\n                                            class_mode=\"categorical\",\n                                            classes = class_names,\n                                            target_size=config.target_size,\n                                            batch_size=config.batch_size)\n\n        try:\n            if isinstance(task, OpenMLSupervisedTask):\n                print(f\"Training ({len(X_train)} samples)\")\n\n\n                if config.perform_validation:\n                    model_copy.fit(train_generator,\n                    steps_per_epoch=config.step_per_epoch,\n                    validation_data = valid_generator, \n                    validation_steps =  valid_generator.n//valid_generator.batch_size,\n                    epochs=config.epoch,\n                    **kwargs)\n\n                else:\n                    model_copy.fit(train_generator,\n                    steps_per_epoch=config.step_per_epoch,\n                    epochs=config.epoch,\n                    **kwargs)\n\n                #print('model_trained')\n\n        except AttributeError as e:\n            # typically happens when training a regressor on classification task\n            raise PyOpenMLError(str(e))\n\n        #class_mapping = train_generator.class_indices  \n        #print(\"Class mapping\",class_mapping)\n        #classes_ordered = sorted(class_mapping, key=class_mapping.get)\n        #print(\"Classes ordered\",classes_ordered)\n        # In supervised learning this returns the predictions for Y\n\n        #print(\"X test\",X_test)\n        datagen_test = ImageDataGenerator()\n        test_generator = datagen_test.flow_from_dataframe(dataframe=X_test, \n                                             directory=config.dir,\n                                             class_mode=None,\n                                             x_col=config.x_col,\n                                             batch_size=32,\n                                             shuffle=False,\n                                             target_size=config.target_size)\n        print(f\"Testing ({len(X_test)} samples)\")\n        if isinstance(task, OpenMLSupervisedTask):\n            pred_y = model_copy.predict(test_generator)\n            proba_y = pred_y\n            if isinstance(task, OpenMLClassificationTask):\n                pred_y = np.argmax(pred_y, axis=-1)\n                #print(\"preds\", pred_y)\n            #elif isinstance(task, OpenMLRegressionTask):\n            #    pred_y = tensorflow.keras.backend.reshape(pred_y, (-1,))\n            #pred_y = tensorflow.keras.backend.eval(pred_y)  \n        else:\n            raise ValueError(task)\n\n        # Remap the probabilities in case there was a class missing at training time\n        # By default, the classification targets are mapped to be zero-based indices\n        # to the actual classes. Therefore, the model_classes contain the correct\n        # indices to the correct probability array. Example:\n        # classes in the dataset: 0, 1, 2, 3, 4, 5\n        # classes in the training set: 0, 1, 2, 4, 5\n        # then we need to add a column full of zeros into the probabilities for class 3\n        # (because the rest of the library expects that the probabilities are ordered\n        # the same way as the classes are ordered).\n        if isinstance(task, OpenMLClassificationTask):\n            if task.class_labels is not None:\n                if proba_y.shape[1] != len(task.class_labels):\n                    model_classes = np.sort(X_train['labels'].astype('int').unique())\n                    proba_y_new = np.zeros((proba_y.shape[0], len(task.class_labels)))\n                    for idx, model_class in enumerate(model_classes):\n                        proba_y_new[:, model_class] = proba_y[:, idx]\n                    proba_y = proba_y_new\n\n                if proba_y.shape[1] != len(task.class_labels):\n                    message = \"Estimator only predicted for {}/{} classes!\".format(\n                        proba_y.shape[1], len(task.class_labels),\n                    )\n                    warnings.warn(message)\n                    openml.config.logger.warn(message)\n\n        elif isinstance(task, OpenMLRegressionTask):\n            proba_y = None\n        else:\n            raise TypeError(type(task))\n\n        # Adjust prediction labels according to train_generator\n        # pred_y = [int(classes_ordered[p_y]) for p_y in pred_y]\n        pred_y = [class_names[i] for i in pred_y]\n\n        #pred_y = le.inverse_transform(pred_y)\n        #print(\"pred classes\", pred_y)\n\n        #pred_y = pred_y.astype('str')\n        #print(\"pred inverse encoded str\", pred_y)\n\n        # Convert the TensorFlow model to ONNX\n        onnx_model, _ = tf2onnx.convert.from_keras(model_copy, opset=13)\n        onnx_ = onnx_model.SerializeToString()\n        global last_models\n        last_models = onnx_\n\n        return pred_y, proba_y, user_defined_measures, None\n\n    def compile_additional_information(\n            self,\n            task: 'OpenMLTask',\n            additional_information: List[Tuple[int, int, Any]]\n    ) -&gt; Dict[str, Tuple[str, str]]:\n        \"\"\"Compiles additional information provided by the extension during the runs into a final\n        set of files.\n\n        Parameters\n        ----------\n        task : OpenMLTask\n            The task the model was run on.\n        additional_information: List[Tuple[int, int, Any]]\n            A list of (fold, repetition, additional information) tuples obtained during training.\n\n        Returns\n        -------\n        files : Dict[str, Tuple[str, str]]\n            A dictionary of files with their file name and contents.\n        \"\"\"\n        return dict()\n\n    def obtain_parameter_values(\n            self,\n            flow: 'OpenMLFlow',\n            model: Any = None,\n    ) -&gt; List[Dict[str, Any]]:\n        \"\"\"Extracts all parameter settings required for the flow from the model.\n\n        If no explicit model is provided, the parameters will be extracted from `flow.model`\n        instead.\n\n        Parameters\n        ----------\n        flow : OpenMLFlow\n            OpenMLFlow object (containing flow ids, i.e., it has to be downloaded from the server)\n\n        model: Any, optional (default=None)\n            The model from which to obtain the parameter values. Must match the flow signature.\n            If None, use the model specified in ``OpenMLFlow.model``.\n\n        Returns\n        -------\n        list\n            A list of dicts, where each dict has the following entries:\n            - ``oml:name`` : str: The OpenML parameter name\n            - ``oml:value`` : mixed: A representation of the parameter value\n            - ``oml:component`` : int: flow id to which the parameter belongs\n        \"\"\"\n        openml.flows.functions._check_flow_for_server_id(flow)\n\n        def get_flow_dict(_flow):\n            flow_map = {_flow.name: _flow.flow_id}\n            for subflow in _flow.components:\n                flow_map.update(get_flow_dict(_flow.components[subflow]))\n            return flow_map\n\n        def extract_parameters(_flow, _flow_dict, component_model,\n                               _main_call=False, main_id=None):\n            # _flow is openml flow object, _param dict maps from flow name to flow\n            # id for the main call, the param dict can be overridden (useful for\n            # unit tests / sentinels) this way, for flows without subflows we do\n            # not have to rely on _flow_dict\n            exp_parameters = set(_flow.parameters)\n            exp_components = set(_flow.components)\n\n            _model_parameters = self._get_parameters(component_model)\n\n            model_parameters = set(_model_parameters.keys())\n            if len((exp_parameters | exp_components) ^ model_parameters) != 0:\n                flow_params = sorted(exp_parameters | exp_components)\n                model_params = sorted(model_parameters)\n                raise ValueError('Parameters of the model do not match the '\n                                 'parameters expected by the '\n                                 'flow:\\nexpected flow parameters: '\n                                 '%s\\nmodel parameters: %s' % (flow_params,\n                                                               model_params))\n\n            _params = []\n            for _param_name in _flow.parameters:\n                _current = OrderedDict()\n                _current['oml:name'] = _param_name\n\n                current_param_values = self.model_to_flow(_model_parameters[_param_name])\n\n                # Try to filter out components (a.k.a. subflows) which are\n                # handled further down in the code (by recursively calling\n                # this function)!\n                if isinstance(current_param_values, openml.flows.OpenMLFlow):\n                    continue\n\n                # vanilla parameter value\n                parsed_values = json.dumps(current_param_values)\n                if len(current_param_values)&gt;2000:\n                   current_param_values = current_param_values[0:1000]\n                _current['oml:value'] = parsed_values\n                if _main_call:\n                    _current['oml:component'] = main_id\n                else:\n                    _current['oml:component'] = _flow_dict[_flow.name]\n                _params.append(_current)\n\n            for _identifier in _flow.components:\n                subcomponent_model = self._get_parameters(component_model)[_identifier]\n                _params.extend(extract_parameters(_flow.components[_identifier],\n                                                  _flow_dict, subcomponent_model))\n            return _params\n\n        flow_dict = get_flow_dict(flow)\n        model = model if model is not None else flow.model\n        parameters = extract_parameters(flow, flow_dict, model, True, flow.flow_id)\n\n        return parameters\n\n    def _openml_param_name_to_keras(\n            self,\n            openml_parameter: openml.setups.OpenMLParameter,\n            flow: OpenMLFlow,\n    ) -&gt; str:\n        \"\"\"\n        Converts the name of an OpenMLParameter into the Keras name, given a flow.\n\n        Parameters\n        ----------\n        openml_parameter: OpenMLParameter\n            The parameter under consideration\n\n        flow: OpenMLFlow\n            The flow that provides context.\n\n        Returns\n        -------\n        keras_parameter_name: str\n            The name the parameter will have once used in Keras\n        \"\"\"\n        if not isinstance(openml_parameter, openml.setups.OpenMLParameter):\n            raise ValueError('openml_parameter should be an instance of OpenMLParameter')\n        if not isinstance(flow, OpenMLFlow):\n            raise ValueError('flow should be an instance of OpenMLFlow')\n\n        flow_structure = flow.get_structure('name')\n        if openml_parameter.flow_name not in flow_structure:\n            raise ValueError('Obtained OpenMLParameter and OpenMLFlow do not correspond. ')\n        name = openml_parameter.flow_name  # for PEP8\n        return '__'.join(flow_structure[name] + [openml_parameter.parameter_name])\n\n    def instantiate_model_from_hpo_class(\n            self,\n            model: Any,\n            trace_iteration: OpenMLTraceIteration,\n    ) -&gt; Any:\n        \"\"\"Instantiate a ``base_estimator`` which can be searched over by the hyperparameter\n        optimization model (UNUSED)\n\n        Parameters\n        ----------\n        model : Any\n            A hyperparameter optimization model which defines the model to be instantiated.\n        trace_iteration : OpenMLTraceIteration\n            Describing the hyperparameter settings to instantiate.\n\n        Returns\n        -------\n        Any\n        \"\"\"\n\n        return model\n    def check_if_model_fitted(self, model: Any) -&gt; bool:\n        \"\"\"Returns True/False denoting if the model has already been fitted/trained\n        Parameters\n        ----------\n        model : Any\n        Returns\n        -------\n        bool\n        \"\"\"\n</code></pre>"},{"location":"API%20reference/OpenML%20integration/#extension.TensorflowExtension.can_handle_flow","title":"<code>can_handle_flow(flow)</code>  <code>classmethod</code>","text":"<p>Check whether a given flow describes a Keras neural network.</p> <p>This is done by parsing the <code>external_version</code> field.</p>"},{"location":"API%20reference/OpenML%20integration/#extension.TensorflowExtension.can_handle_flow--parameters","title":"Parameters","text":"<p>flow : OpenMLFlow</p>"},{"location":"API%20reference/OpenML%20integration/#extension.TensorflowExtension.can_handle_flow--returns","title":"Returns","text":"<p>bool</p> Source code in <code>openml_tensorflow/extension.py</code> <pre><code>@classmethod\ndef can_handle_flow(cls, flow: 'OpenMLFlow') -&gt; bool:\n    \"\"\"Check whether a given flow describes a Keras neural network.\n\n    This is done by parsing the ``external_version`` field.\n\n    Parameters\n    ----------\n    flow : OpenMLFlow\n\n    Returns\n    -------\n    bool\n    \"\"\"\n    return cls._is_tf_flow(flow)\n</code></pre>"},{"location":"API%20reference/OpenML%20integration/#extension.TensorflowExtension.can_handle_model","title":"<code>can_handle_model(model)</code>  <code>classmethod</code>","text":"<p>Check whether a model is an instance of <code>tf.models.Model</code>.</p>"},{"location":"API%20reference/OpenML%20integration/#extension.TensorflowExtension.can_handle_model--parameters","title":"Parameters","text":"<p>model : Any</p>"},{"location":"API%20reference/OpenML%20integration/#extension.TensorflowExtension.can_handle_model--returns","title":"Returns","text":"<p>bool</p> Source code in <code>openml_tensorflow/extension.py</code> <pre><code>@classmethod\ndef can_handle_model(cls, model: Any) -&gt; bool:\n    \"\"\"Check whether a model is an instance of ``tf.models.Model``.\n\n    Parameters\n    ----------\n    model : Any\n\n    Returns\n    -------\n    bool\n    \"\"\"\n    return isinstance(model, tensorflow.keras.models.Model)\n</code></pre>"},{"location":"API%20reference/OpenML%20integration/#extension.TensorflowExtension.check_if_model_fitted","title":"<code>check_if_model_fitted(model)</code>","text":"<p>Returns True/False denoting if the model has already been fitted/trained Parameters</p> <p>model : Any Returns</p> <p>bool</p> Source code in <code>openml_tensorflow/extension.py</code> <pre><code>def check_if_model_fitted(self, model: Any) -&gt; bool:\n    \"\"\"Returns True/False denoting if the model has already been fitted/trained\n    Parameters\n    ----------\n    model : Any\n    Returns\n    -------\n    bool\n    \"\"\"\n</code></pre>"},{"location":"API%20reference/OpenML%20integration/#extension.TensorflowExtension.compile_additional_information","title":"<code>compile_additional_information(task, additional_information)</code>","text":"<p>Compiles additional information provided by the extension during the runs into a final set of files.</p>"},{"location":"API%20reference/OpenML%20integration/#extension.TensorflowExtension.compile_additional_information--parameters","title":"Parameters","text":"<p>task : OpenMLTask     The task the model was run on. additional_information: List[Tuple[int, int, Any]]     A list of (fold, repetition, additional information) tuples obtained during training.</p>"},{"location":"API%20reference/OpenML%20integration/#extension.TensorflowExtension.compile_additional_information--returns","title":"Returns","text":"<p>files : Dict[str, Tuple[str, str]]     A dictionary of files with their file name and contents.</p> Source code in <code>openml_tensorflow/extension.py</code> <pre><code>def compile_additional_information(\n        self,\n        task: 'OpenMLTask',\n        additional_information: List[Tuple[int, int, Any]]\n) -&gt; Dict[str, Tuple[str, str]]:\n    \"\"\"Compiles additional information provided by the extension during the runs into a final\n    set of files.\n\n    Parameters\n    ----------\n    task : OpenMLTask\n        The task the model was run on.\n    additional_information: List[Tuple[int, int, Any]]\n        A list of (fold, repetition, additional information) tuples obtained during training.\n\n    Returns\n    -------\n    files : Dict[str, Tuple[str, str]]\n        A dictionary of files with their file name and contents.\n    \"\"\"\n    return dict()\n</code></pre>"},{"location":"API%20reference/OpenML%20integration/#extension.TensorflowExtension.create_setup_string","title":"<code>create_setup_string(model)</code>","text":"<p>Create a string which can be used to reinstantiate the given model.</p>"},{"location":"API%20reference/OpenML%20integration/#extension.TensorflowExtension.create_setup_string--parameters","title":"Parameters","text":"<p>model : Any</p>"},{"location":"API%20reference/OpenML%20integration/#extension.TensorflowExtension.create_setup_string--returns","title":"Returns","text":"<p>str</p> Source code in <code>openml_tensorflow/extension.py</code> <pre><code>def create_setup_string(self, model: Any) -&gt; str:\n    \"\"\"Create a string which can be used to reinstantiate the given model.\n\n    Parameters\n    ----------\n    model : Any\n\n    Returns\n    -------\n    str\n    \"\"\"\n    run_environment = \" \".join(self.get_version_information())\n    return run_environment + \" \" + str(model)\n</code></pre>"},{"location":"API%20reference/OpenML%20integration/#extension.TensorflowExtension.flow_to_model","title":"<code>flow_to_model(flow, initialize_with_defaults=False)</code>","text":"<p>Initializes a Keras model based on a flow.</p>"},{"location":"API%20reference/OpenML%20integration/#extension.TensorflowExtension.flow_to_model--parameters","title":"Parameters","text":"<p>flow : mixed     the object to deserialize (can be flow object, or any serialized     parameter value that is accepted by)</p> bool, optional (default=False) <p>If this flag is set, the hyperparameter values of flows will be ignored and a flow with its defaults is returned.</p>"},{"location":"API%20reference/OpenML%20integration/#extension.TensorflowExtension.flow_to_model--returns","title":"Returns","text":"<p>mixed</p> Source code in <code>openml_tensorflow/extension.py</code> <pre><code>def flow_to_model(self, flow: 'OpenMLFlow', initialize_with_defaults: bool = False) -&gt; Any:\n    \"\"\"Initializes a Keras model based on a flow.\n\n    Parameters\n    ----------\n    flow : mixed\n        the object to deserialize (can be flow object, or any serialized\n        parameter value that is accepted by)\n\n    initialize_with_defaults : bool, optional (default=False)\n        If this flag is set, the hyperparameter values of flows will be\n        ignored and a flow with its defaults is returned.\n\n    Returns\n    -------\n    mixed\n    \"\"\"\n    return self._deserialize_tf(flow, initialize_with_defaults=initialize_with_defaults)\n</code></pre>"},{"location":"API%20reference/OpenML%20integration/#extension.TensorflowExtension.get_version_information","title":"<code>get_version_information()</code>","text":"<p>List versions of libraries required by the flow.</p> <p>Libraries listed are <code>Python</code>, <code>tensorflow</code>, <code>numpy</code> and <code>scipy</code>.</p>"},{"location":"API%20reference/OpenML%20integration/#extension.TensorflowExtension.get_version_information--returns","title":"Returns","text":"<p>List</p> Source code in <code>openml_tensorflow/extension.py</code> <pre><code>def get_version_information(self) -&gt; List[str]:\n    \"\"\"List versions of libraries required by the flow.\n\n    Libraries listed are ``Python``, ``tensorflow``, ``numpy`` and ``scipy``.\n\n    Returns\n    -------\n    List\n    \"\"\"\n\n    import tensorflow\n    import scipy\n    import numpy\n\n    major, minor, micro, _, _ = sys.version_info\n    python_version = 'Python_{}.'.format(\n        \".\".join([str(major), str(minor), str(micro)]))\n    tensorflow_version = 'tensorflow_{}.'.format(tensorflow.__version__)\n    numpy_version = 'NumPy_{}.'.format(numpy.__version__)\n    scipy_version = 'SciPy_{}.'.format(scipy.__version__)\n\n    return [python_version, tensorflow_version, numpy_version, scipy_version]\n</code></pre>"},{"location":"API%20reference/OpenML%20integration/#extension.TensorflowExtension.instantiate_model_from_hpo_class","title":"<code>instantiate_model_from_hpo_class(model, trace_iteration)</code>","text":"<p>Instantiate a <code>base_estimator</code> which can be searched over by the hyperparameter optimization model (UNUSED)</p>"},{"location":"API%20reference/OpenML%20integration/#extension.TensorflowExtension.instantiate_model_from_hpo_class--parameters","title":"Parameters","text":"<p>model : Any     A hyperparameter optimization model which defines the model to be instantiated. trace_iteration : OpenMLTraceIteration     Describing the hyperparameter settings to instantiate.</p>"},{"location":"API%20reference/OpenML%20integration/#extension.TensorflowExtension.instantiate_model_from_hpo_class--returns","title":"Returns","text":"<p>Any</p> Source code in <code>openml_tensorflow/extension.py</code> <pre><code>def instantiate_model_from_hpo_class(\n        self,\n        model: Any,\n        trace_iteration: OpenMLTraceIteration,\n) -&gt; Any:\n    \"\"\"Instantiate a ``base_estimator`` which can be searched over by the hyperparameter\n    optimization model (UNUSED)\n\n    Parameters\n    ----------\n    model : Any\n        A hyperparameter optimization model which defines the model to be instantiated.\n    trace_iteration : OpenMLTraceIteration\n        Describing the hyperparameter settings to instantiate.\n\n    Returns\n    -------\n    Any\n    \"\"\"\n\n    return model\n</code></pre>"},{"location":"API%20reference/OpenML%20integration/#extension.TensorflowExtension.is_estimator","title":"<code>is_estimator(model)</code>","text":"<p>Check whether the given model is a Keras neural network.</p> <p>This function is only required for backwards compatibility and will be removed in the near future.</p>"},{"location":"API%20reference/OpenML%20integration/#extension.TensorflowExtension.is_estimator--parameters","title":"Parameters","text":"<p>model : Any</p>"},{"location":"API%20reference/OpenML%20integration/#extension.TensorflowExtension.is_estimator--returns","title":"Returns","text":"<p>bool</p> Source code in <code>openml_tensorflow/extension.py</code> <pre><code>def is_estimator(self, model: Any) -&gt; bool:\n    \"\"\"Check whether the given model is a Keras neural network.\n\n    This function is only required for backwards compatibility and will be removed in the\n    near future.\n\n    Parameters\n    ----------\n    model : Any\n\n    Returns\n    -------\n    bool\n    \"\"\"\n    return isinstance(model, tensorflow.keras.models.Model)\n</code></pre>"},{"location":"API%20reference/OpenML%20integration/#extension.TensorflowExtension.model_to_flow","title":"<code>model_to_flow(model)</code>","text":"<p>Transform a Keras model to a flow for uploading it to OpenML.</p>"},{"location":"API%20reference/OpenML%20integration/#extension.TensorflowExtension.model_to_flow--parameters","title":"Parameters","text":"<p>model : Any</p>"},{"location":"API%20reference/OpenML%20integration/#extension.TensorflowExtension.model_to_flow--returns","title":"Returns","text":"<p>OpenMLFlow</p> Source code in <code>openml_tensorflow/extension.py</code> <pre><code>def model_to_flow(self, model: Any) -&gt; 'OpenMLFlow':\n    \"\"\"Transform a Keras model to a flow for uploading it to OpenML.\n\n    Parameters\n    ----------\n    model : Any\n\n    Returns\n    -------\n    OpenMLFlow\n    \"\"\"\n    # Necessary to make pypy not complain about all the different possible return types\n    return self._serialize_tf(model)\n</code></pre>"},{"location":"API%20reference/OpenML%20integration/#extension.TensorflowExtension.obtain_parameter_values","title":"<code>obtain_parameter_values(flow, model=None)</code>","text":"<p>Extracts all parameter settings required for the flow from the model.</p> <p>If no explicit model is provided, the parameters will be extracted from <code>flow.model</code> instead.</p>"},{"location":"API%20reference/OpenML%20integration/#extension.TensorflowExtension.obtain_parameter_values--parameters","title":"Parameters","text":"<p>flow : OpenMLFlow     OpenMLFlow object (containing flow ids, i.e., it has to be downloaded from the server)</p> Any, optional (default=None) <p>The model from which to obtain the parameter values. Must match the flow signature. If None, use the model specified in <code>OpenMLFlow.model</code>.</p>"},{"location":"API%20reference/OpenML%20integration/#extension.TensorflowExtension.obtain_parameter_values--returns","title":"Returns","text":"<p>list     A list of dicts, where each dict has the following entries:     - <code>oml:name</code> : str: The OpenML parameter name     - <code>oml:value</code> : mixed: A representation of the parameter value     - <code>oml:component</code> : int: flow id to which the parameter belongs</p> Source code in <code>openml_tensorflow/extension.py</code> <pre><code>def obtain_parameter_values(\n        self,\n        flow: 'OpenMLFlow',\n        model: Any = None,\n) -&gt; List[Dict[str, Any]]:\n    \"\"\"Extracts all parameter settings required for the flow from the model.\n\n    If no explicit model is provided, the parameters will be extracted from `flow.model`\n    instead.\n\n    Parameters\n    ----------\n    flow : OpenMLFlow\n        OpenMLFlow object (containing flow ids, i.e., it has to be downloaded from the server)\n\n    model: Any, optional (default=None)\n        The model from which to obtain the parameter values. Must match the flow signature.\n        If None, use the model specified in ``OpenMLFlow.model``.\n\n    Returns\n    -------\n    list\n        A list of dicts, where each dict has the following entries:\n        - ``oml:name`` : str: The OpenML parameter name\n        - ``oml:value`` : mixed: A representation of the parameter value\n        - ``oml:component`` : int: flow id to which the parameter belongs\n    \"\"\"\n    openml.flows.functions._check_flow_for_server_id(flow)\n\n    def get_flow_dict(_flow):\n        flow_map = {_flow.name: _flow.flow_id}\n        for subflow in _flow.components:\n            flow_map.update(get_flow_dict(_flow.components[subflow]))\n        return flow_map\n\n    def extract_parameters(_flow, _flow_dict, component_model,\n                           _main_call=False, main_id=None):\n        # _flow is openml flow object, _param dict maps from flow name to flow\n        # id for the main call, the param dict can be overridden (useful for\n        # unit tests / sentinels) this way, for flows without subflows we do\n        # not have to rely on _flow_dict\n        exp_parameters = set(_flow.parameters)\n        exp_components = set(_flow.components)\n\n        _model_parameters = self._get_parameters(component_model)\n\n        model_parameters = set(_model_parameters.keys())\n        if len((exp_parameters | exp_components) ^ model_parameters) != 0:\n            flow_params = sorted(exp_parameters | exp_components)\n            model_params = sorted(model_parameters)\n            raise ValueError('Parameters of the model do not match the '\n                             'parameters expected by the '\n                             'flow:\\nexpected flow parameters: '\n                             '%s\\nmodel parameters: %s' % (flow_params,\n                                                           model_params))\n\n        _params = []\n        for _param_name in _flow.parameters:\n            _current = OrderedDict()\n            _current['oml:name'] = _param_name\n\n            current_param_values = self.model_to_flow(_model_parameters[_param_name])\n\n            # Try to filter out components (a.k.a. subflows) which are\n            # handled further down in the code (by recursively calling\n            # this function)!\n            if isinstance(current_param_values, openml.flows.OpenMLFlow):\n                continue\n\n            # vanilla parameter value\n            parsed_values = json.dumps(current_param_values)\n            if len(current_param_values)&gt;2000:\n               current_param_values = current_param_values[0:1000]\n            _current['oml:value'] = parsed_values\n            if _main_call:\n                _current['oml:component'] = main_id\n            else:\n                _current['oml:component'] = _flow_dict[_flow.name]\n            _params.append(_current)\n\n        for _identifier in _flow.components:\n            subcomponent_model = self._get_parameters(component_model)[_identifier]\n            _params.extend(extract_parameters(_flow.components[_identifier],\n                                              _flow_dict, subcomponent_model))\n        return _params\n\n    flow_dict = get_flow_dict(flow)\n    model = model if model is not None else flow.model\n    parameters = extract_parameters(flow, flow_dict, model, True, flow.flow_id)\n\n    return parameters\n</code></pre>"},{"location":"API%20reference/OpenML%20integration/#extension.TensorflowExtension.seed_model","title":"<code>seed_model(model, seed=None)</code>","text":"<p>Not applied for Keras, since there are no random states in Keras.</p>"},{"location":"API%20reference/OpenML%20integration/#extension.TensorflowExtension.seed_model--parameters","title":"Parameters","text":"<p>model : keras model     The model to be seeded seed : int     The seed to initialize the RandomState with. Unseeded subcomponents     will be seeded with a random number from the RandomState.</p>"},{"location":"API%20reference/OpenML%20integration/#extension.TensorflowExtension.seed_model--returns","title":"Returns","text":"<p>Any</p> Source code in <code>openml_tensorflow/extension.py</code> <pre><code>def seed_model(self, model: Any, seed: Optional[int] = None) -&gt; Any:\n    \"\"\"\n    Not applied for Keras, since there are no random states in Keras.\n\n    Parameters\n    ----------\n    model : keras model\n        The model to be seeded\n    seed : int\n        The seed to initialize the RandomState with. Unseeded subcomponents\n        will be seeded with a random number from the RandomState.\n\n    Returns\n    -------\n    Any\n    \"\"\"\n\n    return model\n</code></pre>"},{"location":"Docker%20reference/Docker/","title":"OpenML-Tensorflow container","text":"<p>The docker container has the latest version of OpenML-Tensorflow downloaded and pre-installed. It can be used to run TensorFlow Deep Learning analysis on OpenML datasets.  This document contains information about:</p> <p>Usage: how to use the image</p> <p>Using Locally Stored Datasets: mounting datasets from the local cache</p> <p>Environment Variables: setting the cache directory path</p>"},{"location":"Docker%20reference/Docker/#usage","title":"Usage","text":"<p>These are the steps to use the image:</p> <ol> <li>Pull the docker image  <pre><code>docker pull openml/openml-tensorflow:latest\n</code></pre></li> <li>If you want to run a local script, it needs to be mounted first. Mount it into the 'app' folder: <pre><code>docker run -it -v PATH/TO/CODE_FOLDER:/app openml/openml-tensorflow /bin/bash\n</code></pre> You can also mount multiple directories into the container (such as your code file directory and dataset directory ) using: <pre><code>docker run -t -i -v PATH/TO/CODE_FOLDER:/app -v PATH/TO/DATASET_FOLDER:/app/dataset openml/openml-tensorflow /bin/bash\n</code></pre></li> <li>Please make sure to give the correct path to the dataset. For example,  <pre><code>openml_tensorflow.config.dir = 'dataset/Images'\n</code></pre></li> <li>Run your code scripts using, for example: <pre><code> python docs/Examples/tf_image_classification.py\n</code></pre></li> </ol>"},{"location":"Docker%20reference/Docker/#using-locally-stored-datasets","title":"Using Locally Stored Datasets","text":"<p>If you don't want to download the dataset each time you run your script, you can mount your dataset saved in your local cache directory to the container. </p>"},{"location":"Docker%20reference/Docker/#example-usage","title":"Example Usage","text":"<ol> <li>Mount the dataset to the 'app/dataset' folder</li> </ol> <pre><code>docker run -t -i -v PATH/TO/CODE_FOLDER:/app -v PATH/TO/DATASET_FOLDER:/app/dataset openml/openml-tensorflow /bin/bash\n</code></pre> <ol> <li>Set correct path to the dataset.  </li> </ol> <pre><code>openml_tensorflow.config.dir = '/app/dataset/Images'\n</code></pre>"},{"location":"Docker%20reference/Docker/#environment-variable","title":"Environment Variable","text":"<p>You can configure the cache directory to control where 'OpenML' datasets are downloaded and cached.</p> <pre><code>cache_dir = \"/app/.openml\"\nopenml.config.set_root_cache_directory(cache_dir)\n</code></pre>"},{"location":"Examples/","title":"Examples","text":"<p>This folder contains examples of how to use the <code>openml-tensorflow</code> extension for different datasets and models. </p>"},{"location":"Examples/tf_image_classification/","title":"Tensorflow image classification model example I","text":"In\u00a0[\u00a0]: Copied! <pre>%matplotlib inline\n</pre> %matplotlib inline In\u00a0[\u00a0]: Copied! <pre>import openml\nimport openml_tensorflow\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\n</pre> import openml import openml_tensorflow from tensorflow.keras.preprocessing.image import ImageDataGenerator import tensorflow as tf from tensorflow.keras import layers, models In\u00a0[\u00a0]: Copied! <pre>openml.config.apikey = 'KEY' # Paste your API key here\n</pre> openml.config.apikey = 'KEY' # Paste your API key here In\u00a0[\u00a0]: Copied! <pre>openml_tensorflow.config.epoch = 1 #  small epoch for test runs\n\ndatagen = ImageDataGenerator()\nopenml_tensorflow.config.datagen = datagen\nopenml_tensorflow.config.dir = openml.config.get_cache_directory()+'/datasets/44312/PNU_Micro/images/'\nopenml_tensorflow.config.x_col = \"FILE_NAME\"\nopenml_tensorflow.config.y_col = 'encoded_labels'\nopenml_tensorflow.config.datagen = datagen\nopenml_tensorflow.config.batch_size = 32\nopenml_tensorflow.config.class_mode = \"categorical\"\n\n# Perform cross-validation during traning \nopenml_tensorflow.config.perform_validation = True\nopenml_tensorflow.config.validation_split = 0.1\nopenml_tensorflow.config.datagen_valid = ImageDataGenerator()\n\nIMG_SIZE = (128, 128)\nIMG_SHAPE = IMG_SIZE + (3,)\n\n# Example tensorflow image classification model. \nmodel = models.Sequential()\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu', input_shape=IMG_SHAPE))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dense(84, activation='relu'))\nmodel.add(layers.Dense(19, activation='softmax'))  # Adjust output size\nmodel.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['AUC'])\n</pre> openml_tensorflow.config.epoch = 1 #  small epoch for test runs  datagen = ImageDataGenerator() openml_tensorflow.config.datagen = datagen openml_tensorflow.config.dir = openml.config.get_cache_directory()+'/datasets/44312/PNU_Micro/images/' openml_tensorflow.config.x_col = \"FILE_NAME\" openml_tensorflow.config.y_col = 'encoded_labels' openml_tensorflow.config.datagen = datagen openml_tensorflow.config.batch_size = 32 openml_tensorflow.config.class_mode = \"categorical\"  # Perform cross-validation during traning  openml_tensorflow.config.perform_validation = True openml_tensorflow.config.validation_split = 0.1 openml_tensorflow.config.datagen_valid = ImageDataGenerator()  IMG_SIZE = (128, 128) IMG_SHAPE = IMG_SIZE + (3,)  # Example tensorflow image classification model.  model = models.Sequential() model.add(layers.Conv2D(128, (3, 3), activation='relu', input_shape=IMG_SHAPE)) model.add(layers.MaxPooling2D((2, 2))) model.add(layers.Conv2D(64, (3, 3), activation='relu')) model.add(layers.MaxPooling2D((2, 2))) model.add(layers.Conv2D(64, (3, 3), activation='relu')) model.add(layers.Flatten()) model.add(layers.Dense(64, activation='relu')) model.add(layers.Dense(84, activation='relu')) model.add(layers.Dense(19, activation='softmax'))  # Adjust output size model.compile(optimizer='adam',               loss='categorical_crossentropy',               metrics=['AUC']) In\u00a0[\u00a0]: Copied! <pre># Download the OpenML task for the Meta_Album_PNU_Micro dataset.\ntask = openml.tasks.get_task(362071)\n\n# Run the Keras model on the task (requires an API key).\nrun = openml.runs.run_model_on_task(model, task, avoid_duplicate_runs=False)\n</pre> # Download the OpenML task for the Meta_Album_PNU_Micro dataset. task = openml.tasks.get_task(362071)  # Run the Keras model on the task (requires an API key). run = openml.runs.run_model_on_task(model, task, avoid_duplicate_runs=False) <p>If you want to publish the run with the onnx file, then you must call openml_tensorflow.add_onnx_to_run() immediately before run.publish(). When you publish, onnx file of last trained model is uploaded. Careful to not call this function when another run_model_on_task is called in between, as during publish later, only the last trained model (from last run_model_on_task call) is uploaded.</p> In\u00a0[\u00a0]: Copied! <pre>run = openml_tensorflow.add_onnx_to_run(run)\n\nrun.publish()\n\nprint('URL for run: %s/run/%d?api_key=%s' % (openml.config.server, run.run_id, openml.config.apikey))\n</pre> run = openml_tensorflow.add_onnx_to_run(run)  run.publish()  print('URL for run: %s/run/%d?api_key=%s' % (openml.config.server, run.run_id, openml.config.apikey)) <p>Optional: Visualize model in netron</p> In\u00a0[\u00a0]: Copied! <pre>from urllib.request import urlretrieve\n\npublished_run = openml.runs.get_run(run.run_id)\nurl = 'https://api.openml.org/data/download/{}/model.onnx'.format(published_run.output_files['onnx_model'])\n\nfile_path, _ = urlretrieve(url, 'model.onnx')\n\nimport netron\n# Visualize the ONNX model using Netron\nnetron.start(file_path)\n</pre> from urllib.request import urlretrieve  published_run = openml.runs.get_run(run.run_id) url = 'https://api.openml.org/data/download/{}/model.onnx'.format(published_run.output_files['onnx_model'])  file_path, _ = urlretrieve(url, 'model.onnx')  import netron # Visualize the ONNX model using Netron netron.start(file_path)"},{"location":"Examples/tf_image_classification/#tensorflow-image-classification-model-example-i","title":"Tensorflow image classification model example I\u00b6","text":"<p>An example of a Tensorflow network that classifies Meta Album images.</p>"},{"location":"Examples/tf_image_classification_Indoorscenes_dataset/","title":"Tensorflow image dataset classification model example II","text":"In\u00a0[\u00a0]: Copied! <pre>%matplotlib inline\n</pre> %matplotlib inline In\u00a0[\u00a0]: Copied! <pre>import os\nimport logging\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nos.environ['ABSL_MIN_LOG_LEVEL'] = '3'\n# logging.getLogger('tensorflow').setLevel(logging.ERROR)\n\nimport tensorflow\n\nimport openml\nimport openml_tensorflow\nimport pandas as pd\nfrom sklearn import preprocessing\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport tensorflow as tf\nfrom tensorflow.keras import datasets, layers, models\nimport logging\nfrom keras import regularizers\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\nimport pandas as pd\npd.options.mode.chained_assignment = None  # default='warn'\n</pre>   import os import logging os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' os.environ['ABSL_MIN_LOG_LEVEL'] = '3' # logging.getLogger('tensorflow').setLevel(logging.ERROR)  import tensorflow  import openml import openml_tensorflow import pandas as pd from sklearn import preprocessing from tensorflow.keras.preprocessing.image import ImageDataGenerator import tensorflow as tf from tensorflow.keras import datasets, layers, models import logging from keras import regularizers  import warnings warnings.simplefilter(action='ignore', category=FutureWarning)  import pandas as pd pd.options.mode.chained_assignment = None  # default='warn' <p>Enable logging in order to observe the progress while running the example.</p> In\u00a0[\u00a0]: Copied! <pre>openml.config.logger.setLevel(logging.DEBUG)\n</pre> openml.config.logger.setLevel(logging.DEBUG) In\u00a0[\u00a0]: Copied! <pre>openml.config.apikey = 'KEY'\n</pre> openml.config.apikey = 'KEY' In\u00a0[\u00a0]: Copied! <pre>openml_tensorflow.config.epoch = 1 #  small epoch for test runs\n\nIMG_SIZE = (128, 128)\nIMG_SHAPE = IMG_SIZE + (3,)\nbase_learning_rate = 0.0001\n\n# Toy example\ndatagen = ImageDataGenerator(\n    rotation_range=25,\n    width_shift_range=0.01,\n    height_shift_range=0.01,\n    brightness_range=(0.9, 1.1),\n    zoom_range=0.1,\n    horizontal_flip=True,\n    vertical_flip=True,\n)\n\nopenml_tensorflow.config.datagen = datagen\nopenml_tensorflow.config.dir = openml.config.get_cache_directory()+'/datasets/45936/Images/'\nopenml_tensorflow.config.x_col = \"Filename\"\nopenml_tensorflow.config.y_col = 'Class_encoded'\nopenml_tensorflow.config.datagen = datagen\nopenml_tensorflow.config.batch_size = 32\nopenml_tensorflow.config.class_mode = \"categorical\"\nopenml_tensorflow.config.perform_validation = True\n\nkwargs = {\n    'callbacks': tf.keras.callbacks.EarlyStopping(monitor='auc', patience=5),\n    'verbose': 2\n}\nopenml_tensorflow.config.kwargs = kwargs\n</pre> openml_tensorflow.config.epoch = 1 #  small epoch for test runs  IMG_SIZE = (128, 128) IMG_SHAPE = IMG_SIZE + (3,) base_learning_rate = 0.0001  # Toy example datagen = ImageDataGenerator(     rotation_range=25,     width_shift_range=0.01,     height_shift_range=0.01,     brightness_range=(0.9, 1.1),     zoom_range=0.1,     horizontal_flip=True,     vertical_flip=True, )  openml_tensorflow.config.datagen = datagen openml_tensorflow.config.dir = openml.config.get_cache_directory()+'/datasets/45936/Images/' openml_tensorflow.config.x_col = \"Filename\" openml_tensorflow.config.y_col = 'Class_encoded' openml_tensorflow.config.datagen = datagen openml_tensorflow.config.batch_size = 32 openml_tensorflow.config.class_mode = \"categorical\" openml_tensorflow.config.perform_validation = True  kwargs = {     'callbacks': tf.keras.callbacks.EarlyStopping(monitor='auc', patience=5),     'verbose': 2 } openml_tensorflow.config.kwargs = kwargs  <p>Large CNN</p> In\u00a0[\u00a0]: Copied! <pre>IMG_SIZE = 128\nNUM_CLASSES = 67\n\n# Example tensorflow image classification model. You can do better :)\nmodel = models.Sequential()\n\n# 4 VGG-like CNN blocks\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same',\n                        input_shape=(IMG_SIZE, IMG_SIZE, 3)))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Dropout(0.2))\n\n\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Dropout(0.3))\n\n\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Dropout(0.4))\n\nmodel.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Dropout(0.5))\n\n# Pooling and one dense layer + output layer\nmodel.add(layers.GlobalAveragePooling2D())\nmodel.add(layers.Dense(192, activation='relu', kernel_regularizer=regularizers.L2(1e-4)))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Dropout(0.25))\nmodel.add(layers.Dense(NUM_CLASSES, activation='softmax'))\n\nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['AUC'])\n</pre> IMG_SIZE = 128 NUM_CLASSES = 67  # Example tensorflow image classification model. You can do better :) model = models.Sequential()  # 4 VGG-like CNN blocks model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same',                         input_shape=(IMG_SIZE, IMG_SIZE, 3))) model.add(layers.BatchNormalization()) model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same')) model.add(layers.BatchNormalization()) model.add(layers.MaxPooling2D((2, 2))) model.add(layers.Dropout(0.2))   model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same')) model.add(layers.BatchNormalization()) model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same')) model.add(layers.BatchNormalization()) model.add(layers.MaxPooling2D((2, 2))) model.add(layers.Dropout(0.3))   model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same')) model.add(layers.BatchNormalization()) model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same')) model.add(layers.BatchNormalization()) model.add(layers.MaxPooling2D((2, 2))) model.add(layers.Dropout(0.4))  model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same')) model.add(layers.BatchNormalization()) model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same')) model.add(layers.BatchNormalization()) model.add(layers.MaxPooling2D((2, 2))) model.add(layers.Dropout(0.5))  # Pooling and one dense layer + output layer model.add(layers.GlobalAveragePooling2D()) model.add(layers.Dense(192, activation='relu', kernel_regularizer=regularizers.L2(1e-4))) model.add(layers.BatchNormalization()) model.add(layers.Dropout(0.25)) model.add(layers.Dense(NUM_CLASSES, activation='softmax'))  model.compile(     optimizer='adam',     loss='categorical_crossentropy',     metrics=['AUC']) In\u00a0[\u00a0]: Copied! <pre># Download the OpenML task for the Indoorscenes dataset.\n\n# task = openml.tasks.get_task(362065)\ntask = openml.tasks.get_task(362070)\n\n# Run the Keras model on the task (requires an API key).\nrun = openml.runs.run_model_on_task(model, task, avoid_duplicate_runs=False)\n\n# If you want to publish the run with the onnx file, \n# then you must call openml_tensorflow.add_onnx_to_run() immediately before run.publish(). \n# When you publish, onnx file of last trained model is uploaded. \n# Careful to not call this function when another run_model_on_task is called in between, \n# as during publish later, only the last trained model (from last run_model_on_task call) is uploaded.   \nrun = openml_tensorflow.add_onnx_to_run(run)\n\nrun.publish()\n\nprint('URL for run: %s/run/%d?api_key=%s' % (openml.config.server, run.run_id, openml.config.apikey))\n</pre> # Download the OpenML task for the Indoorscenes dataset.  # task = openml.tasks.get_task(362065) task = openml.tasks.get_task(362070)  # Run the Keras model on the task (requires an API key). run = openml.runs.run_model_on_task(model, task, avoid_duplicate_runs=False)  # If you want to publish the run with the onnx file,  # then you must call openml_tensorflow.add_onnx_to_run() immediately before run.publish().  # When you publish, onnx file of last trained model is uploaded.  # Careful to not call this function when another run_model_on_task is called in between,  # as during publish later, only the last trained model (from last run_model_on_task call) is uploaded.    run = openml_tensorflow.add_onnx_to_run(run)  run.publish()  print('URL for run: %s/run/%d?api_key=%s' % (openml.config.server, run.run_id, openml.config.apikey)) In\u00a0[\u00a0]: Copied! <pre># Visualize model in netron\n\nfrom urllib.request import urlretrieve\n\npublished_run = openml.runs.get_run(run.run_id)\nurl = 'https://api.openml.org/data/download/{}/model.onnx'.format(published_run.output_files['onnx_model'])\n\nfile_path, _ = urlretrieve(url, 'model.onnx')\n\nimport netron\n# Visualize the ONNX model using Netron\nnetron.start(file_path)\n</pre> # Visualize model in netron  from urllib.request import urlretrieve  published_run = openml.runs.get_run(run.run_id) url = 'https://api.openml.org/data/download/{}/model.onnx'.format(published_run.output_files['onnx_model'])  file_path, _ = urlretrieve(url, 'model.onnx')  import netron # Visualize the ONNX model using Netron netron.start(file_path)"},{"location":"Examples/tf_image_classification_Indoorscenes_dataset/#tensorflow-image-dataset-classification-model-example-ii","title":"Tensorflow image dataset classification model example II\u00b6","text":"<p>An example of a tensorflow network that classifies IndoorScenes images into <code>67</code> classes using tensorflow <code>Sequential</code> model.</p>"},{"location":"Examples/tf_image_classification_sanity_check/","title":"Performance check of tensorflow image classification model","text":"In\u00a0[\u00a0]: Copied! <pre>%matplotlib inline\n</pre> %matplotlib inline In\u00a0[\u00a0]: Copied! <pre>import openml\nimport openml_tensorflow\n\nimport os\nimport pandas as pd\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport tensorflow as tf\nfrom tensorflow.keras import datasets, layers, models\nimport logging\n\nfrom sklearn.model_selection import train_test_split\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.simplefilter(action='ignore', category=UserWarning)\nwarnings.simplefilter(action='ignore', category=RuntimeWarning)\nwarnings.simplefilter(action='ignore')\n\nimport pandas as pd\npd.options.mode.chained_assignment = None  # default='warn'\n</pre> import openml import openml_tensorflow  import os import pandas as pd from tensorflow.keras.preprocessing.image import ImageDataGenerator import tensorflow as tf from tensorflow.keras import datasets, layers, models import logging  from sklearn.model_selection import train_test_split  import warnings warnings.simplefilter(action='ignore', category=FutureWarning) warnings.simplefilter(action='ignore', category=UserWarning) warnings.simplefilter(action='ignore', category=RuntimeWarning) warnings.simplefilter(action='ignore')  import pandas as pd pd.options.mode.chained_assignment = None  # default='warn' <p>Enable logging in order to observe the progress while running the example.</p> In\u00a0[\u00a0]: Copied! <pre>openml.config.logger.setLevel(logging.DEBUG)\n</pre> openml.config.logger.setLevel(logging.DEBUG) In\u00a0[\u00a0]: Copied! <pre>openml.config.apikey = 'KEY'\n</pre> openml.config.apikey = 'KEY' In\u00a0[\u00a0]: Copied! <pre>openml_tensorflow.config.epoch = 1 #  small epoch for test runs\n\nIMG_SIZE = (128, 128)\nIMG_SHAPE = IMG_SIZE + (3,)\nbase_learning_rate = 0.0001\n\ndatagen = ImageDataGenerator()\nopenml_tensorflow.config.datagen = datagen\nopenml_tensorflow.config.dir = openml.config.get_cache_directory()+'/datasets/44312/PNU_Micro/images/'\nopenml_tensorflow.config.x_col = \"FILE_NAME\"\nopenml_tensorflow.config.y_col = 'encoded_labels'\nopenml_tensorflow.config.datagen = datagen\nopenml_tensorflow.config.batch_size = 32\nopenml_tensorflow.config.class_mode = \"categorical\"\n\ndata_augmentation = tf.keras.Sequential([\n  layers.RandomFlip(\"horizontal_and_vertical\"),\n  layers.RandomRotation(0.2),\n])\n\n# Example tensorflow image classification model. You can do better :)\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu', input_shape=(128, 128, 3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dense(84, activation='relu'))\nmodel.add(layers.Dense(67, activation='softmax'))  # Adjust output size\nmodel.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n# task = openml.tasks.get_task(362071)\n\n\n\nopenml_dataset = openml.datasets.get_dataset(45923, download_all_files=True)\ndf, *_ = openml_dataset.get_data()\n\n# Local directory with the images\ndata_dir = os.path.join(os.path.dirname(openml_dataset.data_file), \"Images\")\n\n# Splitting the data\ndf_train, df_valid = train_test_split(df, test_size=0.1, random_state=42, stratify=df['Class_name'])\n\ndatagen_train = ImageDataGenerator() # You can add data augmentation options here.\ntrain_generator = datagen_train.flow_from_dataframe(dataframe=df_train,\n                                            directory=data_dir,\n                                            x_col=\"Filename\", y_col=\"Class_encoded\",\n                                            class_mode=\"categorical\",\n                                            target_size=(IMG_SIZE, IMG_SIZE),\n                                            batch_size=32)\n\nhistory = model.fit(train_generator, steps_per_epoch=openml_tensorflow.config.step_per_epoch,\n                                batch_size=openml_tensorflow.config.batch_size, epochs=openml_tensorflow.config.epoch, verbose=1)\nlearning_curves = history.history\n</pre> openml_tensorflow.config.epoch = 1 #  small epoch for test runs  IMG_SIZE = (128, 128) IMG_SHAPE = IMG_SIZE + (3,) base_learning_rate = 0.0001  datagen = ImageDataGenerator() openml_tensorflow.config.datagen = datagen openml_tensorflow.config.dir = openml.config.get_cache_directory()+'/datasets/44312/PNU_Micro/images/' openml_tensorflow.config.x_col = \"FILE_NAME\" openml_tensorflow.config.y_col = 'encoded_labels' openml_tensorflow.config.datagen = datagen openml_tensorflow.config.batch_size = 32 openml_tensorflow.config.class_mode = \"categorical\"  data_augmentation = tf.keras.Sequential([   layers.RandomFlip(\"horizontal_and_vertical\"),   layers.RandomRotation(0.2), ])  # Example tensorflow image classification model. You can do better :) model = models.Sequential() model.add(layers.Conv2D(128, (3, 3), activation='relu', input_shape=(128, 128, 3))) model.add(layers.MaxPooling2D((2, 2))) model.add(layers.Conv2D(64, (3, 3), activation='relu')) model.add(layers.MaxPooling2D((2, 2))) model.add(layers.Conv2D(64, (3, 3), activation='relu')) model.add(layers.Flatten()) model.add(layers.Dense(64, activation='relu')) model.add(layers.Dense(84, activation='relu')) model.add(layers.Dense(67, activation='softmax'))  # Adjust output size model.compile(optimizer='adam',               loss='categorical_crossentropy',               metrics=['accuracy'])  # task = openml.tasks.get_task(362071)    openml_dataset = openml.datasets.get_dataset(45923, download_all_files=True) df, *_ = openml_dataset.get_data()  # Local directory with the images data_dir = os.path.join(os.path.dirname(openml_dataset.data_file), \"Images\")  # Splitting the data df_train, df_valid = train_test_split(df, test_size=0.1, random_state=42, stratify=df['Class_name'])  datagen_train = ImageDataGenerator() # You can add data augmentation options here. train_generator = datagen_train.flow_from_dataframe(dataframe=df_train,                                             directory=data_dir,                                             x_col=\"Filename\", y_col=\"Class_encoded\",                                             class_mode=\"categorical\",                                             target_size=(IMG_SIZE, IMG_SIZE),                                             batch_size=32)  history = model.fit(train_generator, steps_per_epoch=openml_tensorflow.config.step_per_epoch,                                 batch_size=openml_tensorflow.config.batch_size, epochs=openml_tensorflow.config.epoch, verbose=1) learning_curves = history.history"},{"location":"Examples/tf_image_classification_sanity_check/#performance-check-of-tensorflow-image-classification-model","title":"Performance check of tensorflow image classification model\u00b6","text":"<p>This example demonstrates how to build and train a TensorFlow network that classifies images from the Meta Album Images dataset on OpenML. The model runs independently and can be used as a sanity check to compare results generated using <code> openml.runs.run_model_on_task</code>.</p>"},{"location":"Examples/tf_pretrained_model_Indoorscenes_dataset/","title":"Tensorflow image classification using pre-trained model example II","text":"In\u00a0[\u00a0]: Copied! <pre>%matplotlib inline\n</pre> %matplotlib inline In\u00a0[\u00a0]: Copied! <pre>import logging\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nos.environ['ABSL_MIN_LOG_LEVEL'] = '3'\nlogging.getLogger('tensorflow').setLevel(logging.ERROR)\n\nimport openml\nimport openml_tensorflow\n\nimport pandas as pd\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.applications import EfficientNetV2B3\n\nimport warnings\nwarnings.simplefilter(action='ignore')\n\nimport pandas as pd\npd.options.mode.chained_assignment = None  # default='warn'\n</pre>  import logging import os os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' os.environ['ABSL_MIN_LOG_LEVEL'] = '3' logging.getLogger('tensorflow').setLevel(logging.ERROR)  import openml import openml_tensorflow  import pandas as pd from tensorflow.keras.preprocessing.image import ImageDataGenerator import tensorflow as tf from tensorflow.keras import layers, models from tensorflow.keras.applications import EfficientNetV2B3  import warnings warnings.simplefilter(action='ignore')  import pandas as pd pd.options.mode.chained_assignment = None  # default='warn' <p>Enable logging in order to observe the progress while running the example.</p> In\u00a0[\u00a0]: Copied! <pre>openml.config.logger.setLevel(logging.DEBUG)\n</pre> openml.config.logger.setLevel(logging.DEBUG) In\u00a0[\u00a0]: Copied! <pre>openml.config.apikey = 'KEY'\n</pre> openml.config.apikey = 'KEY' In\u00a0[\u00a0]: Copied! <pre>openml_tensorflow.config.epoch = 1 #  small epoch for test runs\n\nIMG_SIZE = (128, 128)\nIMG_SHAPE = IMG_SIZE + (3,)\nbase_learning_rate = 0.0001\n\n# datagen = ImageDataGenerator(\n#             rotation_range=20,            # Degree range for random rotations\n#             width_shift_range=0.2,        # Fraction of total width for random horizontal shifts\n#             height_shift_range=0.2,       # Fraction of total height for random vertical shifts\n#             shear_range=0.2,              # Shear intensity (shear angle in radians)\n#             zoom_range=0.2,               # Random zoom range\n#             horizontal_flip=True,         # Randomly flip inputs horizontally\n#             fill_mode='nearest',\n#             validation_split=0.2\n#         )\n\ndatagen = ImageDataGenerator()\nopenml_tensorflow.config.datagen = datagen\n\nopenml_tensorflow.config.dir = openml.config.get_cache_directory()+'/datasets/45923/Images/'\n# openml_tensorflow.config.dir = 'dataset/Images'\nopenml_tensorflow.config.x_col = \"Filename\"\nopenml_tensorflow.config.y_col = 'Class_encoded'\nopenml_tensorflow.config.datagen = datagen\nopenml_tensorflow.config.batch_size = 2\nopenml_tensorflow.config.class_mode = \"categorical\"\nopenml_tensorflow.config.perform_validation = True\n\nkwargs = {\n    'callbacks': tf.keras.callbacks.EarlyStopping(monitor='loss', patience=0),\n    'verbose': 2\n}\nopenml_tensorflow.config.kwargs = kwargs\n\nIMG_SIZE = 128\nNUM_CLASSES = 67\n\ndef build_model():\n    \n    dropout_rate = 0.6\n\n    base = EfficientNetV2B3(\n        include_top=False,\n        weights=\"imagenet\",\n        pooling=None)\n    count = 0\n    count_trainable = 0\t\n    for layer in base.layers:\n        if count &gt;= len(base.layers) - 10:\n            layer.trainable = True\n            count_trainable += 1\n        else:\n            layer.trainable = False\n        count += 1\n\n    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n    x = base(inputs, training=False)\n    x = layers.GlobalAveragePooling2D()(x)\n    x = layers.Dense(512, activation='relu')(x)\n    x = layers.Dropout(dropout_rate)(x)\n    x = layers.Dense(256, activation='relu')(x)\n    x = layers.Dropout(dropout_rate)(x)\n    outputs = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n    model = models.Model(inputs=inputs, outputs=outputs)\n    model.compile(optimizer='adam',\n              loss='categorical_crossentropy',  # Ensure that you're passing it as a string\n              metrics=['accuracy'])\n    print(count_trainable)\n    return model\n</pre> openml_tensorflow.config.epoch = 1 #  small epoch for test runs  IMG_SIZE = (128, 128) IMG_SHAPE = IMG_SIZE + (3,) base_learning_rate = 0.0001  # datagen = ImageDataGenerator( #             rotation_range=20,            # Degree range for random rotations #             width_shift_range=0.2,        # Fraction of total width for random horizontal shifts #             height_shift_range=0.2,       # Fraction of total height for random vertical shifts #             shear_range=0.2,              # Shear intensity (shear angle in radians) #             zoom_range=0.2,               # Random zoom range #             horizontal_flip=True,         # Randomly flip inputs horizontally #             fill_mode='nearest', #             validation_split=0.2 #         )  datagen = ImageDataGenerator() openml_tensorflow.config.datagen = datagen  openml_tensorflow.config.dir = openml.config.get_cache_directory()+'/datasets/45923/Images/' # openml_tensorflow.config.dir = 'dataset/Images' openml_tensorflow.config.x_col = \"Filename\" openml_tensorflow.config.y_col = 'Class_encoded' openml_tensorflow.config.datagen = datagen openml_tensorflow.config.batch_size = 2 openml_tensorflow.config.class_mode = \"categorical\" openml_tensorflow.config.perform_validation = True  kwargs = {     'callbacks': tf.keras.callbacks.EarlyStopping(monitor='loss', patience=0),     'verbose': 2 } openml_tensorflow.config.kwargs = kwargs  IMG_SIZE = 128 NUM_CLASSES = 67  def build_model():          dropout_rate = 0.6      base = EfficientNetV2B3(         include_top=False,         weights=\"imagenet\",         pooling=None)     count = 0     count_trainable = 0\t     for layer in base.layers:         if count &gt;= len(base.layers) - 10:             layer.trainable = True             count_trainable += 1         else:             layer.trainable = False         count += 1      inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))     x = base(inputs, training=False)     x = layers.GlobalAveragePooling2D()(x)     x = layers.Dense(512, activation='relu')(x)     x = layers.Dropout(dropout_rate)(x)     x = layers.Dense(256, activation='relu')(x)     x = layers.Dropout(dropout_rate)(x)     outputs = layers.Dense(NUM_CLASSES, activation='softmax')(x)     model = models.Model(inputs=inputs, outputs=outputs)     model.compile(optimizer='adam',               loss='categorical_crossentropy',  # Ensure that you're passing it as a string               metrics=['accuracy'])     print(count_trainable)     return model In\u00a0[\u00a0]: Copied! <pre># Download the OpenML task for the Indoorscenes dataset.\n\n# task = openml.tasks.get_task(362065)#   10 fold cross validation \ntask = openml.tasks.get_task(362070)#   3 fold cross validation\n\nmodel = build_model()\n\n# Run the model on the task (requires an API key).\nrun = openml.runs.run_model_on_task(model, task, avoid_duplicate_runs=False)\n\n# If you want to publish the run with the onnx file, \n# then you must call openml_tensorflow.add_onnx_to_run() immediately before run.publish(). \n# When you publish, onnx file of last trained model is uploaded. \n# Careful to not call this function when another run_model_on_task is called in between, \n# as during publish later, only the last trained model (from last run_model_on_task call) is uploaded.   \nrun = openml_tensorflow.add_onnx_to_run(run)\n\nrun.publish()\n\nprint('URL for run: %s/run/%d?api_key=%s' % (openml.config.server, run.run_id, openml.config.apikey))\n</pre> # Download the OpenML task for the Indoorscenes dataset.  # task = openml.tasks.get_task(362065)#   10 fold cross validation  task = openml.tasks.get_task(362070)#   3 fold cross validation  model = build_model()  # Run the model on the task (requires an API key). run = openml.runs.run_model_on_task(model, task, avoid_duplicate_runs=False)  # If you want to publish the run with the onnx file,  # then you must call openml_tensorflow.add_onnx_to_run() immediately before run.publish().  # When you publish, onnx file of last trained model is uploaded.  # Careful to not call this function when another run_model_on_task is called in between,  # as during publish later, only the last trained model (from last run_model_on_task call) is uploaded.    run = openml_tensorflow.add_onnx_to_run(run)  run.publish()  print('URL for run: %s/run/%d?api_key=%s' % (openml.config.server, run.run_id, openml.config.apikey)) In\u00a0[\u00a0]: Copied! <pre># Visualize model in netron\n\nfrom urllib.request import urlretrieve\n\npublished_run = openml.runs.get_run(run.run_id)\nurl = 'https://api.openml.org/data/download/{}/model.onnx'.format(published_run.output_files['onnx_model'])\n\nfile_path, _ = urlretrieve(url, 'model.onnx')\n\nimport netron\n# Visualize the ONNX model using Netron\nnetron.start(file_path)\n\n# URL for run: https://www.openml.org/api/v1/xml/run/10594206\n</pre> # Visualize model in netron  from urllib.request import urlretrieve  published_run = openml.runs.get_run(run.run_id) url = 'https://api.openml.org/data/download/{}/model.onnx'.format(published_run.output_files['onnx_model'])  file_path, _ = urlretrieve(url, 'model.onnx')  import netron # Visualize the ONNX model using Netron netron.start(file_path)  # URL for run: https://www.openml.org/api/v1/xml/run/10594206"},{"location":"Examples/tf_pretrained_model_Indoorscenes_dataset/#tensorflow-image-classification-using-pre-trained-model-example-ii","title":"Tensorflow image classification using pre-trained model example II\u00b6","text":"<p>An example of a tensorflow network that classifies Indoor Scenes images using pre-trained transformer model. Here some layers of the pre-trained model are trained while other layers are frozen.</p>"},{"location":"Examples/tf_transfer_learning/","title":"Tensorflow image classification using pre-trained model example I","text":"In\u00a0[\u00a0]: Copied! <pre>%matplotlib inline\n</pre> %matplotlib inline In\u00a0[\u00a0]: Copied! <pre>import openml\nimport openml_tensorflow\nimport pandas as pd\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport tensorflow as tf\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras import optimizers, Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n</pre> import openml import openml_tensorflow import pandas as pd from tensorflow.keras.preprocessing.image import ImageDataGenerator import tensorflow as tf from tensorflow.keras.applications import EfficientNetB0 from tensorflow.keras import optimizers, Model from tensorflow.keras.layers import Dense, GlobalAveragePooling2D In\u00a0[\u00a0]: Copied! <pre>openml.config.apikey = 'KEY' # Paste your API key here\n</pre> openml.config.apikey = 'KEY' # Paste your API key here In\u00a0[\u00a0]: Copied! <pre>openml_tensorflow.config.epoch = 1 #  small epoch for test runs\n\ndatagen = ImageDataGenerator()\nopenml_tensorflow.config.datagen = datagen\nopenml_tensorflow.config.dir = openml.config.get_cache_directory()+'/datasets/45923/Images/'\nopenml_tensorflow.config.x_col = \"Filename\"\nopenml_tensorflow.config.y_col = 'Class_encoded'\nopenml_tensorflow.config.datagen = datagen\nopenml_tensorflow.config.batch_size = 2\nopenml_tensorflow.config.class_mode = \"categorical\"\nopenml_tensorflow.config.perform_validation = True\n\nkwargs = {\n    'callbacks': tf.keras.callbacks.EarlyStopping(monitor='loss', patience=0),\n    'verbose': 2\n}\nopenml_tensorflow.config.kwargs = kwargs\n\nIMG_SIZE = 128\nNUM_CLASSES = 67\nbase_learning_rate = 0.0001\n\n# Example pre-trained model   \nbase_model = EfficientNetB0(input_shape=(IMG_SIZE, IMG_SIZE, 3),\n                        weights=\"imagenet\",\n                        include_top=False)\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\npredictions = Dense(NUM_CLASSES, activation='softmax')(x)\nmodel = Model(inputs=base_model.input, outputs=predictions)\nmodel.compile(optimizers.Adam(learning_rate=4e-4),\n                loss='categorical_crossentropy',\n                metrics=['AUC'])\n</pre> openml_tensorflow.config.epoch = 1 #  small epoch for test runs  datagen = ImageDataGenerator() openml_tensorflow.config.datagen = datagen openml_tensorflow.config.dir = openml.config.get_cache_directory()+'/datasets/45923/Images/' openml_tensorflow.config.x_col = \"Filename\" openml_tensorflow.config.y_col = 'Class_encoded' openml_tensorflow.config.datagen = datagen openml_tensorflow.config.batch_size = 2 openml_tensorflow.config.class_mode = \"categorical\" openml_tensorflow.config.perform_validation = True  kwargs = {     'callbacks': tf.keras.callbacks.EarlyStopping(monitor='loss', patience=0),     'verbose': 2 } openml_tensorflow.config.kwargs = kwargs  IMG_SIZE = 128 NUM_CLASSES = 67 base_learning_rate = 0.0001  # Example pre-trained model    base_model = EfficientNetB0(input_shape=(IMG_SIZE, IMG_SIZE, 3),                         weights=\"imagenet\",                         include_top=False) x = base_model.output x = GlobalAveragePooling2D()(x) predictions = Dense(NUM_CLASSES, activation='softmax')(x) model = Model(inputs=base_model.input, outputs=predictions) model.compile(optimizers.Adam(learning_rate=4e-4),                 loss='categorical_crossentropy',                 metrics=['AUC']) In\u00a0[\u00a0]: Copied! <pre># Download the OpenML task for the Indoor Scenes dataset.\ntask = openml.tasks.get_task(362070)#   3 fold cross validation\n\nmodel = model\n\n# Run the Keras model on the task (requires an API key).\nrun = openml.runs.run_model_on_task(model, task, avoid_duplicate_runs=False)\n</pre> # Download the OpenML task for the Indoor Scenes dataset. task = openml.tasks.get_task(362070)#   3 fold cross validation  model = model  # Run the Keras model on the task (requires an API key). run = openml.runs.run_model_on_task(model, task, avoid_duplicate_runs=False) <p>Note: If you want to publish the run with the onnx file, then you must call openml_tensorflow.add_onnx_to_run() immediately before run.publish(). When you publish, onnx file of last trained model is uploaded. Careful to not call this function when another run_model_on_task is called in between, as during publish later, only the last trained model (from last run_model_on_task call) is uploaded.</p> In\u00a0[\u00a0]: Copied! <pre>run = openml_tensorflow.add_onnx_to_run(run)\n\nrun.publish()\n\nprint('URL for run: %s/run/%d?api_key=%s' % (openml.config.server, run.run_id, openml.config.apikey))\n</pre> run = openml_tensorflow.add_onnx_to_run(run)  run.publish()  print('URL for run: %s/run/%d?api_key=%s' % (openml.config.server, run.run_id, openml.config.apikey)) <p>Optional: Visualize model in netron</p> In\u00a0[\u00a0]: Copied! <pre>from urllib.request import urlretrieve\n\npublished_run = openml.runs.get_run(run.run_id)\nurl = 'https://api.openml.org/data/download/{}/model.onnx'.format(published_run.output_files['onnx_model'])\n\nfile_path, _ = urlretrieve(url, 'model.onnx')\n\nimport netron\n# Visualize the ONNX model using Netron\nnetron.start(file_path)\n</pre> from urllib.request import urlretrieve  published_run = openml.runs.get_run(run.run_id) url = 'https://api.openml.org/data/download/{}/model.onnx'.format(published_run.output_files['onnx_model'])  file_path, _ = urlretrieve(url, 'model.onnx')  import netron # Visualize the ONNX model using Netron netron.start(file_path)"},{"location":"Examples/tf_transfer_learning/#tensorflow-image-classification-using-pre-trained-model-example-i","title":"Tensorflow image classification using pre-trained model example I\u00b6","text":"<p>An example of a tensorflow pre-trained network that classifies indoor scenes images, where all layers are trained. For smaller datasets or datasets similar to the dataset the base model was trained on, it is advisable to freeze pre-trained network, and only train custom layers.</p>"}]}